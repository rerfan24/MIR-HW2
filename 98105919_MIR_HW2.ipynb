{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align:center;'>\n",
    "<h1 style='text-align:center;'>In the name of God</h1>\n",
    "<p> Modern Information Retrival - Sharif Univercity of Technology - Semester: Spring 1401 </p>\n",
    "<p style='font-weight:bold;'> Reza Erfan Arani - 98105919</p>\n",
    "<h5 style='display:inline;'>subject: </h5><span> Information about words in a criticism of a movie </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install following libraries\n",
    "! pip install --user -U nltk\n",
    "! pip install selenium\n",
    "! pip install bs4\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style='display:inline;'>Movie Selected:</h5><span style='color:#907221'> The Shawshank Redemption (1994) </span>\n",
    "<p>In this project I am going to collect every criticism of <i>The Shawshank Redemption</i> from <a href='https://www.imdb.com/title/tt0111161/reviews?ref_=tt_urv'>IMDB User Review</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website has 10k+ criticism, But it has an issue for retrieving it. This webpage designed to have a <i>Load More</i> button at the end of the page. This means that only getting page's content wont be enough and we wont get all of criticisms.\n",
    "<br>\n",
    "So we have to find a way to first click this load more button as long as we get the whole page content and then retrieve the content we want.\n",
    "<br><br>\n",
    "We use <span style='font-size:larger;font-weight:bold;'>Selenium</span> Library to do that and then retrieve the data that we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver      \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know 10k+ is a very very large amount of data, so we only check this for clicking on the 'Load More' button a few times which is changable by changing the for loop number.\n",
    "<br>\n",
    "\n",
    "<p>p.s: You can get all criticisms by uncommenting the <span style='color:#60A2A1'># while True:</span> part and comment the for loop line after that instead in the code cell below!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style='font-size:x-large;'>⚠</span> Please keep in mind that you need a webdriver for this program to work!<br>\n",
    " I personally use Edge webdriver! you can download it from: <a href='https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/'>Microsoft Edge Webdriver Download</a> (it is already in the project folder if you clone it!)<br>\n",
    " If you don't have <i>Microsoft Edge</i> or don't want to use it you can easily download other webdrivers and just put it in the folder beside your code.<br><br>\n",
    " <span><span style='color:#D05221'>Note. </span>If you want to use other webdrivers you should specify it in line 5 below!</span>\n",
    " <span>You can get more information in <a href='https://www.selenium.dev/documentation/webdriver/getting_started/install_drivers/'>Selenium Webdrivers</a></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp/ipykernel_19344/674741403.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(\"./msedgedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "IMDB_PAGE_URL = \"https://www.imdb.com/title/tt0111161/reviews?ref_=tt_urv\"\n",
    "PATIENCE_TIME = 60\n",
    "# LOAD_MORE_BUTTON_XPATH = '//*[@id=\"load-more-trigger\"]' \n",
    "\n",
    "driver = webdriver.Edge(\"./msedgedriver.exe\")\n",
    "driver.get(IMDB_PAGE_URL)\n",
    "\n",
    "# while True:\n",
    "for _ in range(200):\n",
    "    try:\n",
    "        time.sleep(0.2)\n",
    "        loadMoreButton = driver.find_element(By.XPATH, \"//button[text()='Load More']\").click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "print(\"Complete\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now The Datasets that we are going to collect are:\n",
    "1. <span style='color:#50D221'>Scores</span> that each criticism gave to the movie.\n",
    "2. <span style='color:#C0B221'>Date</span> that it was written.\n",
    "3. The text of <span style='color:#30B2E1'>criticism</span> itself!\n",
    "4. Number of criticisms with <span style='color:#D05221'>spoilers</span>!\n",
    "\n",
    "And then we are going to save them into Four .txt files so we don't run the whole <i>get the information from site</i> over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp/ipykernel_19344/4007615588.py:1: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  scores = driver.find_elements_by_xpath('//span[@class=\"rating-other-user-rating\"]/span[1]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores retrieved: 4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp/ipykernel_19344/4007615588.py:3: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  dates = driver.find_elements_by_xpath('//span[@class=\"review-date\"]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates retrieved: 5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp/ipykernel_19344/4007615588.py:5: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  crits = driver.find_elements_by_xpath('//div[@class=\"text show-more__control\"]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criticisms retrieved: 4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp/ipykernel_19344/4007615588.py:7: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  spoilers = driver.find_elements_by_xpath('//span[@class=\"spoiler-warning\"]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spoilers retrieved: 848\n"
     ]
    }
   ],
   "source": [
    "scores = driver.find_elements_by_xpath('//span[@class=\"rating-other-user-rating\"]/span[1]')\n",
    "print('scores retrieved:', len(scores))\n",
    "dates = driver.find_elements_by_xpath('//span[@class=\"review-date\"]')\n",
    "print('dates retrieved:', len(dates))\n",
    "crits = driver.find_elements_by_xpath('//div[@class=\"text show-more__control\"]')\n",
    "print('Criticisms retrieved:', len(crits))\n",
    "spoilers = driver.find_elements_by_xpath('//span[@class=\"spoiler-warning\"]')\n",
    "print('Spoilers retrieved:', len(spoilers))\n",
    "f = open('scores.txt', 'a', encoding='utf-8')\n",
    "for score in scores:\n",
    "    f.write(f'{score.text}\\n')\n",
    "f.close()\n",
    "f = open('dates.txt', 'a', encoding='utf-8')\n",
    "for date in dates:\n",
    "    f.write(f'{date.text}\\n')\n",
    "f.close()\n",
    "f = open('crits.txt', 'a', encoding='utf-8')\n",
    "for crit in crits:\n",
    "    f.write(f'{crit.text}\\n')\n",
    "f.close()\n",
    "f = open('spoilers.txt', 'a', encoding='utf-8')\n",
    "for spoiler in spoilers:\n",
    "    f.write(f'{spoiler.text}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:x-large;'>⚠</span> Don't forget to close the driver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset we want to do our pre-proccesing tasks on it and get some useful information:\n",
    "\n",
    " <span><span style='color:#D05221'>Note. </span> make sure you download the following resources from nltk download page:</span>\n",
    " \n",
    " 1. stopwords\n",
    " 2. punkt\n",
    " 3. wordnet\n",
    " 4. omw-1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Most common words used in criticisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a better processing we turn all the alphabets to their lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toLower(input):\n",
    "    return input.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(input):\n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deleting stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordsRemoval(input):\n",
    "    stopwordsList = stopwords.words('english')\n",
    "    return [w.lower() for w in input if w not in stopwordsList]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deleting punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuationRemoval(input):\n",
    "    return list(filter(lambda token: token not in string.punctuation, input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find most Frequent words used in the criticisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFreq(input):\n",
    "    return nltk.FreqDist(w.lower() for w in input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "critsString = ''\n",
    "with open('crits.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    critsString = f.read()\n",
    "critsString = critsString.strip()\n",
    "\n",
    "# First we lower case the whole text\n",
    "lowerCritsString = toLower(critsString)\n",
    "\n",
    "# lets just have a normal text without extra spacing between sentences:\n",
    "lowerCritsString = \" \".join(lowerCritsString.split())\n",
    "\n",
    "# Tokenization\n",
    "tokenizedCritsString = tokenization(lowerCritsString)\n",
    "\n",
    "# lets remove stopwords\n",
    "tokenizedCritsStringStopWordsExepct = stopwordsRemoval(tokenizedCritsString)\n",
    "\n",
    "# Removing punctuations\n",
    "tokenizedCritsStringStopWordsPunctuationExepct = punctuationRemoval(tokenizedCritsStringStopWordsExepct)\n",
    "\n",
    "# Find frequency of the words used in critisisms\n",
    "freqTable = findFreq(tokenizedCritsStringStopWordsPunctuationExepct)\n",
    "mostCommon= freqTable.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a beautiful table to show frequency: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie</td>\n",
       "      <td>4961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>film</td>\n",
       "      <td>2306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shawshank</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>watch</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ever</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>movies</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>like</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>redemption</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prison</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>seen</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>freeman</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hope</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>life</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>morgan</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Freq\n",
       "0        movie  4961\n",
       "1         film  2306\n",
       "2          one  1670\n",
       "3         best  1439\n",
       "4         time  1156\n",
       "5        story  1119\n",
       "6        great  1053\n",
       "7    shawshank  1043\n",
       "8        watch  1033\n",
       "9         ever   962\n",
       "10        good   956\n",
       "11      movies   921\n",
       "12        like   880\n",
       "13  redemption   833\n",
       "14      prison   809\n",
       "15        seen   756\n",
       "16     freeman   755\n",
       "17        hope   753\n",
       "18        life   729\n",
       "19      morgan   690"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "freq_analysis = pd.DataFrame(mostCommon, columns=['Word', 'Freq'])\n",
    "freq_analysis.columns\n",
    "freq_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematized 20 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117476/117476 [00:00<00:00, 277801.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(movie, 5882)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(film, 2731)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(one, 1711)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(time, 1520)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(best, 1442)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(story, 1188)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(great, 1066)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(shawshank, 1043)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(watch, 1040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ever, 962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(good, 956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(like, 894)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(prison, 836)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(redemption, 833)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(hope, 792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(life, 785)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(freeman, 765)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(seen, 756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(morgan, 690)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(see, 659)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1\n",
       "0       (movie, 5882)\n",
       "1        (film, 2731)\n",
       "2         (one, 1711)\n",
       "3        (time, 1520)\n",
       "4        (best, 1442)\n",
       "5       (story, 1188)\n",
       "6       (great, 1066)\n",
       "7   (shawshank, 1043)\n",
       "8       (watch, 1040)\n",
       "9         (ever, 962)\n",
       "10        (good, 956)\n",
       "11        (like, 894)\n",
       "12      (prison, 836)\n",
       "13  (redemption, 833)\n",
       "14        (hope, 792)\n",
       "15        (life, 785)\n",
       "16     (freeman, 765)\n",
       "17        (seen, 756)\n",
       "18      (morgan, 690)\n",
       "19         (see, 659)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import tqdm\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "critsLemmatize = [lemmatizer.lemmatize(tok) for tok in tqdm.tqdm(tokenizedCritsStringStopWordsPunctuationExepct)]\n",
    "# critsLemmatize\n",
    "dataframe_nonstop_lemstem = {}\n",
    "dataframe_nonstop_lemstem[1] = nltk.FreqDist(eval(F\"critsLemmatize\")).most_common(20)\n",
    "freq_analysis_nonstop_lemstem = pd.DataFrame(dataframe_nonstop_lemstem)\n",
    "freq_analysis_nonstop_lemstem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion:\n",
    "- As you can see the word 'movie' is the most frequent word used in all criticisms.\n",
    "- Lematized 'movie' is almost founded 1000 times more in the text than regular 'movie' search!\n",
    "- Also you can see that very positive words are among the most frequent words which we can almost interpret that this is a good movie!\n",
    "- Out of all actors/actresses in the movie you can see that <i>Morgan Freeman</i> is the only name that is frequent, which shows either a great acting or fame or both for him!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Criticisms with Spoilers Alert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of criticisms with spoiler: 849\n"
     ]
    }
   ],
   "source": [
    "with open('spoilers.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    spoilersString = f.read()\n",
    "spoilersArray = spoilersString.split('\\n')\n",
    "print(f'Number of criticisms with spoiler: {len(spoilersArray)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Scores of the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate average score of these criticisms by calculating sum of the score data we collect from IMDB and divide it by the number of scores. \n",
    "<br><br>\n",
    "<span><span style='color:#D05221'>Note. </span>Some of the criticisms doesn't have score so we reduce 1 from length of scores to calculate the score correctly</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score given by users is: 9.201400679117148\n"
     ]
    }
   ],
   "source": [
    "with open('scores.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    scoresString = f.read()\n",
    "scoresArray = scoresString.split('\\n')\n",
    "sum = 0\n",
    "n = len(scoresArray)\n",
    "for score in scoresArray:\n",
    "    try:\n",
    "        sum += float(score)\n",
    "    except:\n",
    "        n -= 1\n",
    "print(f'Average score given by users is: {sum/n}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d0bc455fb1f111feac98563baf72197a64f009712bd5d436755204a8bac743f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
